"use strict";

Object.defineProperty(exports, "__esModule", {
  value: true
});
exports.default = void 0;

var _map2 = _interopRequireDefault(require("lodash/fp/map"));

var _uniq2 = _interopRequireDefault(require("lodash/uniq"));

var _result2 = _interopRequireDefault(require("lodash/result"));

var _partial2 = _interopRequireDefault(require("lodash/partial"));

var _last2 = _interopRequireDefault(require("lodash/last"));

var _initial2 = _interopRequireDefault(require("lodash/initial"));

var _hasIn2 = _interopRequireDefault(require("lodash/hasIn"));

var _get2 = _interopRequireDefault(require("lodash/get"));

var _flow2 = _interopRequireDefault(require("lodash/flow"));

var _find2 = _interopRequireDefault(require("lodash/find"));

var _jsBase = require("js-base64");

var _semaphore = _interopRequireDefault(require("semaphore"));

var _netlifyCmsLibUtil = require("netlify-cms-lib-util");

function _interopRequireDefault(obj) { return obj && obj.__esModule ? obj : { default: obj }; }

function _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }

function _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }

function ownKeys(object, enumerableOnly) { var keys = Object.keys(object); if (Object.getOwnPropertySymbols) { var symbols = Object.getOwnPropertySymbols(object); if (enumerableOnly) symbols = symbols.filter(function (sym) { return Object.getOwnPropertyDescriptor(object, sym).enumerable; }); keys.push.apply(keys, symbols); } return keys; }

function _objectSpread(target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i] != null ? arguments[i] : {}; if (i % 2) { ownKeys(source, true).forEach(function (key) { _defineProperty(target, key, source[key]); }); } else if (Object.getOwnPropertyDescriptors) { Object.defineProperties(target, Object.getOwnPropertyDescriptors(source)); } else { ownKeys(source).forEach(function (key) { Object.defineProperty(target, key, Object.getOwnPropertyDescriptor(source, key)); }); } } return target; }

function _defineProperty(obj, key, value) { if (key in obj) { Object.defineProperty(obj, key, { value: value, enumerable: true, configurable: true, writable: true }); } else { obj[key] = value; } return obj; }

const CMS_BRANCH_PREFIX = 'cms';

const replace404WithEmptyArray = err => err && err.status === 404 ? [] : Promise.reject(err);

class API {
  constructor(config) {
    var _this = this;

    _defineProperty(this, "getPRsForBranchName", function () {
      let {
        branchName,
        state,
        base = _this.branch,
        repoURL = _this.repoURL,
        usernameOfFork
      } = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : {};
      // Get PRs with a `head` of `branchName`. Note that this is a
      // substring match, so we need to check that the `head.ref` of
      // at least one of the returned objects matches `branchName`.
      return _this.requestAllPages("".concat(repoURL, "/pulls"), {
        params: _objectSpread({
          head: usernameOfFork ? "".concat(usernameOfFork, ":").concat(branchName) : branchName
        }, state ? {
          state
        } : {}, {
          base
        })
      });
    });

    _defineProperty(this, "branchHasPR", async (_ref) => {
      let {
        branchName
      } = _ref,
          rest = _objectWithoutProperties(_ref, ["branchName"]);

      const prs = await this.getPRsForBranchName(_objectSpread({
        branchName
      }, rest));
      return prs.some(pr => pr.head.ref === branchName);
    });

    _defineProperty(this, "getUpdatedOpenAuthoringMetadata", async function (contentKey) {
      let {
        metadata: metadataArg
      } = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : {};
      const metadata = metadataArg || (await _this.retrieveMetadata(contentKey)) || {};
      const {
        pr: prMetadata,
        status
      } = metadata; // Set the status to draft if no corresponding PR is recorded

      if (!prMetadata && status !== 'draft') {
        const newMetadata = _objectSpread({}, metadata, {
          status: 'draft'
        });

        _this.storeMetadata(contentKey, newMetadata);

        return newMetadata;
      } // If no status is recorded, but there is a PR, check if the PR is
      // closed or not and update the status accordingly.


      if (prMetadata) {
        const {
          number: prNumber
        } = prMetadata;
        const originPRInfo = await _this.getPullRequest(prNumber);
        const {
          state: currentState,
          merged_at: mergedAt
        } = originPRInfo;

        if (currentState === 'closed' && mergedAt) {
          // The PR has been merged; delete the unpublished entry
          const [, collectionName, slug] = contentKey.split('/');

          _this.deleteUnpublishedEntry(collectionName, slug);

          return;
        } else if (currentState === 'closed' && !mergedAt) {
          if (status !== 'draft') {
            const newMetadata = _objectSpread({}, metadata, {
              status: 'draft'
            });

            await _this.storeMetadata(contentKey, newMetadata);
            return newMetadata;
          }
        } else {
          if (status !== 'pending_review') {
            // PR is open and has not been merged
            const newMetadata = _objectSpread({}, metadata, {
              status: 'pending_review'
            });

            await _this.storeMetadata(contentKey, newMetadata);
            return newMetadata;
          }
        }
      }

      return metadata;
    });

    this.api_root = config.api_root || 'https://api.github.com';
    this.token = config.token || false;
    this.branch = config.branch || 'master';
    this.useOpenAuthoring = config.useOpenAuthoring;
    this.repo = config.repo || '';
    this.originRepo = config.originRepo || this.repo;
    this.repoURL = "/repos/".concat(this.repo); // when not in 'useOpenAuthoring' mode originRepoURL === repoURL

    this.originRepoURL = "/repos/".concat(this.originRepo);
    this.merge_method = config.squash_merges ? 'squash' : 'merge';
    this.initialWorkflowStatus = config.initialWorkflowStatus;
  }

  user() {
    if (!this._userPromise) {
      this._userPromise = this.request('/user');
    }

    return this._userPromise;
  }

  hasWriteAccess() {
    return this.request(this.repoURL).then(repo => repo.permissions.push).catch(error => {
      console.error('Problem fetching repo data from GitHub');
      throw error;
    });
  }

  requestHeaders() {
    let headers = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : {};

    const baseHeader = _objectSpread({
      'Content-Type': 'application/json'
    }, headers);

    if (this.token) {
      baseHeader.Authorization = "token ".concat(this.token);
      return baseHeader;
    }

    return baseHeader;
  }

  parseJsonResponse(response) {
    return response.json().then(json => {
      if (!response.ok) {
        return Promise.reject(json);
      }

      return json;
    });
  }

  urlFor(path, options) {
    const cacheBuster = new Date().getTime();
    const params = ["ts=".concat(cacheBuster)];

    if (options.params) {
      for (const key in options.params) {
        params.push("".concat(key, "=").concat(encodeURIComponent(options.params[key])));
      }
    }

    if (params.length) {
      path += "?".concat(params.join('&'));
    }

    return this.api_root + path;
  }

  parseResponse(response) {
    const contentType = response.headers.get('Content-Type');

    if (contentType && contentType.match(/json/)) {
      return this.parseJsonResponse(response);
    }

    const textPromise = response.text().then(text => {
      if (!response.ok) {
        return Promise.reject(text);
      }

      return text;
    });
    return textPromise;
  }

  request(path) {
    let options = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : {};
    let parseResponse = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : response => this.parseResponse(response);
    const headers = this.requestHeaders(options.headers || {});
    const url = this.urlFor(path, options);
    let responseStatus;
    return fetch(url, _objectSpread({}, options, {
      headers
    })).then(response => {
      responseStatus = response.status;
      return parseResponse(response);
    }).catch(error => {
      throw new _netlifyCmsLibUtil.APIError(error.message, responseStatus, 'GitHub');
    });
  }

  async requestAllPages(url) {
    let options = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : {};
    const headers = this.requestHeaders(options.headers || {});
    const processedURL = this.urlFor(url, options);
    const allResponses = await (0, _netlifyCmsLibUtil.getAllResponses)(processedURL, _objectSpread({}, options, {
      headers
    }));
    const pages = await Promise.all(allResponses.map(res => this.parseResponse(res)));
    return [].concat(...pages);
  }

  generateContentKey(collectionName, slug) {
    if (!this.useOpenAuthoring) {
      // this doesn't use the collection, but we need to leave it that way for backwards
      // compatibility
      return slug;
    }

    return "".concat(this.repo, "/").concat(collectionName, "/").concat(slug);
  }

  generateBranchName(contentKey) {
    return "".concat(CMS_BRANCH_PREFIX, "/").concat(contentKey);
  }

  branchNameFromRef(ref) {
    return ref.substring('refs/heads/'.length);
  }

  contentKeyFromRef(ref) {
    return ref.substring("refs/heads/".concat(CMS_BRANCH_PREFIX, "/").length);
  }

  checkMetadataRef() {
    return this.request("".concat(this.repoURL, "/git/refs/meta/_netlify_cms"), {
      cache: 'no-store'
    }).then(response => response.object).catch(() => {
      // Meta ref doesn't exist
      const readme = {
        raw: '# Netlify CMS\n\nThis tree is used by the Netlify CMS to store metadata information for specific files and branches.'
      };
      return this.uploadBlob(readme).then(item => this.request("".concat(this.repoURL, "/git/trees"), {
        method: 'POST',
        body: JSON.stringify({
          tree: [{
            path: 'README.md',
            mode: '100644',
            type: 'blob',
            sha: item.sha
          }]
        })
      })).then(tree => this.commit('First Commit', tree)).then(response => this.createRef('meta', '_netlify_cms', response.sha)).then(response => response.object);
    });
  }

  async storeMetadata(key, data) {
    // semaphore ensures metadata updates are always ordered, even if
    // calls to storeMetadata are not. concurrent metadata updates
    // will result in the metadata branch being unable to update.
    if (!this._metadataSemaphore) {
      this._metadataSemaphore = (0, _semaphore.default)(1);
    }

    return new Promise((resolve, reject) => this._metadataSemaphore.take(async () => {
      try {
        const branchData = await this.checkMetadataRef();
        const fileTree = {
          ["".concat(key, ".json")]: {
            path: "".concat(key, ".json"),
            raw: JSON.stringify(data),
            file: true
          }
        };
        await this.uploadBlob(fileTree["".concat(key, ".json")]);
        const changeTree = await this.updateTree(branchData.sha, '/', fileTree);
        const {
          sha
        } = await this.commit("Updating \u201C".concat(key, "\u201D metadata"), changeTree);
        await this.patchRef('meta', '_netlify_cms', sha);

        _netlifyCmsLibUtil.localForage.setItem("gh.meta.".concat(key), {
          expires: Date.now() + 300000,
          // In 5 minutes
          data
        });

        this._metadataSemaphore.leave();

        resolve();
      } catch (err) {
        reject(err);
      }
    }));
  }

  retrieveMetadata(key) {
    const cache = _netlifyCmsLibUtil.localForage.getItem("gh.meta.".concat(key));

    return cache.then(cached => {
      if (cached && cached.expires > Date.now()) {
        return cached.data;
      }

      console.log('%c Checking for MetaData files', 'line-height: 30px;text-align: center;font-weight: bold');
      const metadataRequestOptions = {
        params: {
          ref: 'refs/meta/_netlify_cms'
        },
        headers: {
          Accept: 'application/vnd.github.VERSION.raw'
        },
        cache: 'no-store'
      };

      const errorHandler = err => {
        if (err.message === 'Not Found') {
          console.log('%c %s does not have metadata', 'line-height: 30px;text-align: center;font-weight: bold', key);
        }

        throw err;
      };

      if (!this.useOpenAuthoring) {
        return this.request("".concat(this.repoURL, "/contents/").concat(key, ".json"), metadataRequestOptions).then(response => JSON.parse(response)).catch(errorHandler);
      }

      const [user, repo] = key.split('/');
      return this.request("/repos/".concat(user, "/").concat(repo, "/contents/").concat(key, ".json"), metadataRequestOptions).then(response => JSON.parse(response)).catch(errorHandler);
    });
  }

  retrieveContent(path, branch, repoURL) {
    return this.request("".concat(repoURL, "/contents/").concat(path), {
      headers: {
        Accept: 'application/vnd.github.VERSION.raw'
      },
      params: {
        ref: branch
      },
      cache: 'no-store'
    }).catch(error => {
      if ((0, _hasIn2.default)(error, 'message.errors') && (0, _find2.default)(error.message.errors, {
        code: 'too_large'
      })) {
        const dir = path.split('/').slice(0, -1).join('/');
        return this.listFiles(dir, {
          repoURL,
          branch
        }).then(files => files.find(file => file.path === path)).then(file => this.getBlob(file.sha, {
          repoURL
        }));
      }

      throw error;
    });
  }

  readFile(path, sha) {
    let {
      branch = this.branch,
      repoURL = this.repoURL
    } = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : {};

    if (sha) {
      return this.getBlob(sha);
    } else {
      return this.retrieveContent(path, branch, repoURL);
    }
  }

  fetchBlob(sha, repoURL) {
    return this.request("".concat(repoURL, "/git/blobs/").concat(sha), {
      headers: {
        Accept: 'application/vnd.github.VERSION.raw'
      }
    }, response => response);
  }

  async fetchBlobContent(sha, repoURL) {
    const response = await this.fetchBlob(sha, repoURL);
    const text = await response.text();
    return text;
  }

  async getMediaDisplayURL(sha, path) {
    const response = await this.fetchBlob(sha, this.repoURL);
    let blob;

    if (path.match(/.svg$/)) {
      const svg = await response.text();
      blob = new Blob([svg], {
        type: 'image/svg+xml'
      });
    } else {
      blob = await response.blob();
    }

    return URL.createObjectURL(blob);
  }

  getBlob(sha) {
    let {
      repoURL = this.repoURL
    } = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : {};
    return _netlifyCmsLibUtil.localForage.getItem("gh.".concat(sha)).then(cached => {
      if (cached) {
        return cached;
      }

      return this.fetchBlobContent(sha, repoURL).then(result => {
        _netlifyCmsLibUtil.localForage.setItem("gh.".concat(sha), result);

        return result;
      });
    });
  }

  listFiles(path) {
    let {
      repoURL = this.repoURL,
      branch = this.branch
    } = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : {};
    return this.request("".concat(repoURL, "/contents/").concat(path.replace(/\/$/, '')), {
      params: {
        ref: branch
      }
    }).then(files => {
      if (!Array.isArray(files)) {
        throw new Error("Cannot list files, path ".concat(path, " is not a directory but a ").concat(files.type));
      }

      return files;
    }).then(files => files.filter(file => file.type === 'file'));
  }

  readUnpublishedBranchFile(contentKey) {
    const metaDataPromise = this.retrieveMetadata(contentKey).then(data => data.objects.entry.path ? data : Promise.reject(null));
    const repoURL = this.useOpenAuthoring ? "/repos/".concat(contentKey.split('/').slice(0, 2).join('/')) : this.repoURL;
    return (0, _netlifyCmsLibUtil.resolvePromiseProperties)({
      metaData: metaDataPromise,
      fileData: metaDataPromise.then(data => this.readFile(data.objects.entry.path, null, {
        branch: data.branch,
        repoURL
      })),
      isModification: metaDataPromise.then(data => this.isUnpublishedEntryModification(data.objects.entry.path, this.branch))
    }).catch(() => {
      throw new _netlifyCmsLibUtil.EditorialWorkflowError('content is not under editorial workflow', true);
    });
  }

  isUnpublishedEntryModification(path, branch) {
    return this.readFile(path, null, {
      branch,
      repoURL: this.originRepoURL
    }).then(() => true).catch(err => {
      if (err.message && err.message === 'Not Found') {
        return false;
      }

      throw err;
    });
  }

  async listUnpublishedBranches() {
    console.log('%c Checking for Unpublished entries', 'line-height: 30px;text-align: center;font-weight: bold');
    const onlyBranchesWithOpenPRs = (0, _netlifyCmsLibUtil.filterPromisesWith)((_ref2) => {
      let {
        ref
      } = _ref2;
      return this.branchHasPR({
        branchName: this.branchNameFromRef(ref),
        state: 'open'
      });
    });
    const getUpdatedOpenAuthoringBranches = (0, _flow2.default)([(0, _map2.default)(async branch => {
      const contentKey = this.contentKeyFromRef(branch.ref);
      const metadata = await this.getUpdatedOpenAuthoringMetadata(contentKey); // filter out removed entries

      if (!metadata) {
        return Promise.reject('Unpublished entry was removed');
      }

      return branch;
    }), _netlifyCmsLibUtil.onlySuccessfulPromises]);

    try {
      const branches = await this.request("".concat(this.repoURL, "/git/refs/heads/cms")).catch(replace404WithEmptyArray);
      const filterFunction = this.useOpenAuthoring ? getUpdatedOpenAuthoringBranches : onlyBranchesWithOpenPRs;
      return await filterFunction(branches);
    } catch (err) {
      console.log('%c No Unpublished entries', 'line-height: 30px;text-align: center;font-weight: bold');
      throw err;
    }
  }
  /**
   * Retrieve statuses for a given SHA. Unrelated to the editorial workflow
   * concept of entry "status". Useful for things like deploy preview links.
   */


  async getStatuses(sha) {
    try {
      const resp = await this.request("".concat(this.originRepoURL, "/commits/").concat(sha, "/status"));
      return resp.statuses;
    } catch (err) {
      if (err && err.message && err.message === 'Ref not found') {
        return [];
      }

      throw err;
    }
  }

  composeFileTree(files) {
    let filename;
    let part;
    let parts;
    let subtree;
    const fileTree = {};
    files.forEach(file => {
      if (file.uploaded) {
        return;
      }

      parts = file.path.split('/').filter(part => part);
      filename = parts.pop();
      subtree = fileTree;

      while (part = parts.shift()) {
        // eslint-disable-line no-cond-assign
        subtree[part] = subtree[part] || {};
        subtree = subtree[part];
      }

      subtree[filename] = file;
      file.file = true;
    });
    return fileTree;
  }

  persistFiles(entry, mediaFiles, options) {
    const uploadPromises = [];
    const files = entry ? mediaFiles.concat(entry) : mediaFiles;
    files.forEach(file => {
      if (file.uploaded) {
        return;
      }

      uploadPromises.push(this.uploadBlob(file));
    });
    const fileTree = this.composeFileTree(files);
    return Promise.all(uploadPromises).then(() => {
      if (!options.useWorkflow) {
        return this.getBranch().then(branchData => this.updateTree(branchData.commit.sha, '/', fileTree)).then(changeTree => this.commit(options.commitMessage, changeTree)).then(response => this.patchBranch(this.branch, response.sha));
      } else {
        const mediaFilesList = mediaFiles.map(file => ({
          path: file.path,
          sha: file.sha
        }));
        return this.editorialWorkflowGit(fileTree, entry, mediaFilesList, options);
      }
    });
  }

  getFileSha(path, branch) {
    /**
     * We need to request the tree first to get the SHA. We use extended SHA-1
     * syntax (<rev>:<path>) to get a blob from a tree without having to recurse
     * through the tree.
     */
    const pathArray = path.split('/');
    const filename = (0, _last2.default)(pathArray);
    const directory = (0, _initial2.default)(pathArray).join('/');
    const fileDataPath = encodeURIComponent(directory);
    const fileDataURL = "".concat(this.repoURL, "/git/trees/").concat(branch, ":").concat(fileDataPath);
    return this.request(fileDataURL, {
      cache: 'no-store'
    }).then(resp => {
      const {
        sha
      } = resp.tree.find(file => file.path === filename);
      return sha;
    });
  }

  deleteFile(path, message) {
    let options = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : {};

    if (this.useOpenAuthoring) {
      return Promise.reject('Cannot delete published entries as an Open Authoring user!');
    }

    const branch = options.branch || this.branch;
    return this.getFileSha(path, branch).then(sha => {
      const opts = {
        method: 'DELETE',
        params: {
          sha,
          message,
          branch
        }
      };

      if (this.commitAuthor) {
        opts.params.author = _objectSpread({}, this.commitAuthor, {
          date: new Date().toISOString()
        });
      }

      const fileURL = "".concat(this.repoURL, "/contents/").concat(path);
      return this.request(fileURL, opts);
    });
  }

  async createBranchAndPullRequest(branchName, sha, commitMessage) {
    await this.createBranch(branchName, sha);
    return this.createPR(commitMessage, branchName);
  }

  async editorialWorkflowGit(fileTree, entry, filesList, options) {
    const contentKey = this.generateContentKey(options.collectionName, entry.slug);
    const branchName = this.generateBranchName(contentKey);
    const unpublished = options.unpublished || false;

    if (!unpublished) {
      // Open new editorial review workflow for this entry - Create new metadata and commit to new branch
      const userPromise = this.user();
      const branchData = await this.getBranch();
      const changeTree = await this.updateTree(branchData.commit.sha, '/', fileTree);
      const commitResponse = await this.commit(options.commitMessage, changeTree);
      let pr;

      if (this.useOpenAuthoring) {
        await this.createBranch(branchName, commitResponse.sha);
      } else {
        pr = await this.createBranchAndPullRequest(branchName, commitResponse.sha, options.commitMessage);
      }

      const user = await userPromise;
      return this.storeMetadata(contentKey, {
        type: 'PR',
        pr: pr ? {
          number: pr.number,
          head: pr.head && pr.head.sha
        } : undefined,
        user: user.name || user.login,
        status: this.initialWorkflowStatus,
        branch: branchName,
        collection: options.collectionName,
        commitMessage: options.commitMessage,
        title: options.parsedData && options.parsedData.title,
        description: options.parsedData && options.parsedData.description,
        objects: {
          entry: {
            path: entry.path,
            sha: entry.sha
          },
          files: filesList
        },
        timeStamp: new Date().toISOString()
      });
    } else {
      // Entry is already on editorial review workflow - just update metadata and commit to existing branch
      const branchData = await this.getBranch(branchName);
      const changeTree = await this.updateTree(branchData.commit.sha, '/', fileTree);
      const commitPromise = this.commit(options.commitMessage, changeTree);
      const metadataPromise = this.retrieveMetadata(contentKey);
      const [commit, metadata] = await Promise.all([commitPromise, metadataPromise]);
      const {
        title,
        description
      } = options.parsedData || {};
      const metadataFiles = (0, _get2.default)(metadata.objects, 'files', []);
      const files = [...metadataFiles, ...filesList];
      const pr = metadata.pr ? _objectSpread({}, metadata.pr, {
        head: commit.sha
      }) : undefined;
      const objects = {
        entry: {
          path: entry.path,
          sha: entry.sha
        },
        files: (0, _uniq2.default)(files)
      };

      const updatedMetadata = _objectSpread({}, metadata, {
        pr,
        title,
        description,
        objects
      });

      if (options.hasAssetStore) {
        await this.storeMetadata(contentKey, updatedMetadata);
        return this.patchBranch(branchName, commit.sha);
      }

      if (pr) {
        return this.rebasePullRequest(pr.number, branchName, contentKey, metadata, commit);
      } else if (this.useOpenAuthoring) {
        // if a PR hasn't been created yet for the forked repo, just patch the branch
        await this.patchBranch(branchName, commit.sha, {
          force: true
        });
      }

      return this.storeMetadata(contentKey, updatedMetadata);
    }
  }
  /**
   * Rebase a pull request onto the latest HEAD of it's target base branch
   * (should generally be the configured backend branch). Only rebases changes
   * in the entry file.
   */


  async rebasePullRequest(prNumber, branchName, contentKey, metadata, head) {
    const {
      path
    } = metadata.objects.entry;

    try {
      /**
       * Get the published branch and create new commits over it. If the pull
       * request is up to date, no rebase will occur.
       */
      const [baseBranch, commits] = await Promise.all([this.getBranch(), this.getPullRequestCommits(prNumber, head)]);
      /**
       * Sometimes the list of commits for a pull request isn't updated
       * immediately after the PR branch is patched. There's also the possibility
       * that the branch has changed unexpectedly. We account for both by adding
       * the head if it's missing, or else throwing an error if the PR head is
       * neither the head we expect nor its parent.
       */

      const finalCommits = this.assertHead(commits, head);
      const rebasedHead = await this.rebaseSingleBlobCommits(baseBranch.commit, finalCommits, path);
      /**
       * Update metadata, then force update the pull request branch head.
       */

      const pr = _objectSpread({}, metadata.pr, {
        head: rebasedHead.sha
      });

      const timeStamp = new Date().toISOString();

      const updatedMetadata = _objectSpread({}, metadata, {
        pr,
        timeStamp
      });

      await this.storeMetadata(contentKey, updatedMetadata);
      return this.patchBranch(branchName, rebasedHead.sha, {
        force: true
      });
    } catch (error) {
      console.error(error);
      throw error;
    }
  }
  /**
   * Rebase an array of commits one-by-one, starting from a given base SHA. Can
   * accept an array of commits as received from the GitHub API. All commits are
   * expected to change the same, single blob.
   */


  rebaseSingleBlobCommits(baseCommit, commits, pathToBlob) {
    /**
     * If the parent of the first commit already matches the target base,
     * return commits as is.
     */
    if (commits.length === 0 || commits[0].parents[0].sha === baseCommit.sha) {
      return Promise.resolve((0, _last2.default)(commits));
    }
    /**
     * Re-create each commit over the new base, applying each to the previous,
     * changing only the parent SHA and tree for each, but retaining all other
     * info, such as the author/committer data.
     */


    const newHeadPromise = commits.reduce((lastCommitPromise, commit) => {
      return lastCommitPromise.then(newParent => {
        /**
         * Normalize commit data to ensure it's not nested in `commit.commit`.
         */
        const parent = this.normalizeCommit(newParent);
        const commitToRebase = this.normalizeCommit(commit);
        return this.rebaseSingleBlobCommit(parent, commitToRebase, pathToBlob);
      });
    }, Promise.resolve(baseCommit));
    /**
     * Return a promise that resolves when all commits have been created.
     */

    return newHeadPromise;
  }
  /**
   * Rebase a commit that changes a single blob. Also handles updating the tree.
   */


  rebaseSingleBlobCommit(baseCommit, commit, pathToBlob) {
    /**
     * Retain original commit metadata.
     */
    const {
      message,
      author,
      committer
    } = commit;
    /**
     * Set the base commit as the parent.
     */

    const parent = [baseCommit.sha];
    /**
     * Get the blob data by path.
     */

    return this.getBlobInTree(commit.tree.sha, pathToBlob)
    /**
     * Create a new tree consisting of the base tree and the single updated
     * blob. Use the full path to indicate nesting, GitHub will take care of
     * subtree creation.
     */
    .then(blob => this.createTree(baseCommit.tree.sha, [_objectSpread({}, blob, {
      path: pathToBlob
    })]))
    /**
     * Create a new commit with the updated tree and original commit metadata.
     */
    .then(tree => this.createCommit(message, tree.sha, parent, author, committer));
  }
  /**
   * Get a pull request by PR number.
   */


  getPullRequest(prNumber) {
    return this.request("".concat(this.originRepoURL, "/pulls/").concat(prNumber, " }"));
  }
  /**
   * Get the list of commits for a given pull request.
   */


  getPullRequestCommits(prNumber) {
    return this.request("".concat(this.originRepoURL, "/pulls/").concat(prNumber, "/commits"));
  }
  /**
   * Returns `commits` with `headToAssert` appended if it's the child of the
   * last commit in `commits`. Returns `commits` unaltered if `headToAssert` is
   * already the last commit in `commits`. Otherwise throws an error.
   */


  assertHead(commits, headToAssert) {
    const headIsMissing = headToAssert.parents[0].sha === (0, _last2.default)(commits).sha;
    const headIsNotMissing = headToAssert.sha === (0, _last2.default)(commits).sha;

    if (headIsMissing) {
      return commits.concat(headToAssert);
    } else if (headIsNotMissing) {
      return commits;
    }

    throw Error('Editorial workflow branch changed unexpectedly.');
  }

  async updateUnpublishedEntryStatus(collectionName, slug, status) {
    const contentKey = this.generateContentKey(collectionName, slug);
    const metadata = await this.retrieveMetadata(contentKey);

    if (!this.useOpenAuthoring) {
      return this.storeMetadata(contentKey, _objectSpread({}, metadata, {
        status
      }));
    }

    if (status === 'pending_publish') {
      throw new Error('Open Authoring entries may not be set to the status "pending_publish".');
    }

    const {
      pr: prMetadata
    } = metadata;

    if (prMetadata) {
      const {
        number: prNumber
      } = prMetadata;
      const originPRInfo = await this.getPullRequest(prNumber);
      const {
        state
      } = originPRInfo;

      if (state === 'open' && status === 'draft') {
        await this.closePR(prMetadata);
        return this.storeMetadata(contentKey, _objectSpread({}, metadata, {
          status
        }));
      }

      if (state === 'closed' && status === 'pending_review') {
        await this.openPR(prMetadata);
        return this.storeMetadata(contentKey, _objectSpread({}, metadata, {
          status
        }));
      }
    }

    if (!prMetadata && status === 'pending_review') {
      const branchName = this.generateBranchName(contentKey);
      const commitMessage = metadata.commitMessage || API.DEFAULT_COMMIT_MESSAGE;
      const {
        number,
        head
      } = await this.createPR(commitMessage, branchName);
      return this.storeMetadata(contentKey, _objectSpread({}, metadata, {
        pr: {
          number,
          head
        },
        status
      }));
    }
  }

  async deleteUnpublishedEntry(collectionName, slug) {
    const contentKey = this.generateContentKey(collectionName, slug);
    const branchName = this.generateBranchName(contentKey);
    return this.retrieveMetadata(contentKey).then(metadata => metadata && metadata.pr ? this.closePR(metadata.pr) : Promise.resolve()).then(() => this.deleteBranch(branchName)) // If the PR doesn't exist, then this has already been deleted -
    // deletion should be idempotent, so we can consider this a
    // success.
    .catch(err => {
      if (err.message === 'Reference does not exist') {
        return Promise.resolve();
      }

      console.error(err);
      return Promise.reject(err);
    });
  }

  publishUnpublishedEntry(collectionName, slug) {
    const contentKey = this.generateContentKey(collectionName, slug);
    const branchName = this.generateBranchName(contentKey);
    return this.retrieveMetadata(contentKey).then(metadata => this.mergePR(metadata.pr, metadata.objects)).then(() => this.deleteBranch(branchName));
  }

  createRef(type, name, sha) {
    return this.request("".concat(this.repoURL, "/git/refs"), {
      method: 'POST',
      body: JSON.stringify({
        ref: "refs/".concat(type, "/").concat(name),
        sha
      })
    });
  }

  patchRef(type, name, sha) {
    let opts = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : {};
    const force = opts.force || false;
    return this.request("".concat(this.repoURL, "/git/refs/").concat(type, "/").concat(encodeURIComponent(name)), {
      method: 'PATCH',
      body: JSON.stringify({
        sha,
        force
      })
    });
  }

  deleteRef(type, name) {
    return this.request("".concat(this.repoURL, "/git/refs/").concat(type, "/").concat(encodeURIComponent(name)), {
      method: 'DELETE'
    });
  }

  getBranch() {
    let branch = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : this.branch;
    return this.request("".concat(this.repoURL, "/branches/").concat(encodeURIComponent(branch)));
  }

  createBranch(branchName, sha) {
    return this.createRef('heads', branchName, sha);
  }

  assertCmsBranch(branchName) {
    return branchName.startsWith("".concat(CMS_BRANCH_PREFIX, "/"));
  }

  patchBranch(branchName, sha) {
    let opts = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : {};
    const force = opts.force || false;

    if (force && !this.assertCmsBranch(branchName)) {
      throw Error("Only CMS branches can be force updated, cannot force update ".concat(branchName));
    }

    return this.patchRef('heads', branchName, sha, {
      force
    });
  }

  deleteBranch(branchName) {
    return this.deleteRef('heads', branchName);
  }

  async createPR(title, head) {
    const headReference = this.useOpenAuthoring ? "".concat((await this.user()).login, ":").concat(head) : head;
    return this.request("".concat(this.originRepoURL, "/pulls"), {
      method: 'POST',
      body: JSON.stringify({
        title,
        body: API.DEFAULT_PR_BODY,
        head: headReference,
        base: this.branch
      })
    });
  }

  async openPR(pullRequest) {
    const {
      number
    } = pullRequest;
    console.log('%c Re-opening PR', 'line-height: 30px;text-align: center;font-weight: bold');
    return this.request("".concat(this.originRepoURL, "/pulls/").concat(number), {
      method: 'PATCH',
      body: JSON.stringify({
        state: 'open'
      })
    });
  }

  closePR(pullRequest) {
    const {
      number
    } = pullRequest;
    console.log('%c Deleting PR', 'line-height: 30px;text-align: center;font-weight: bold');
    return this.request("".concat(this.originRepoURL, "/pulls/").concat(number), {
      method: 'PATCH',
      body: JSON.stringify({
        state: 'closed'
      })
    });
  }

  mergePR(pullrequest, objects) {
    const {
      head: headSha,
      number
    } = pullrequest;
    console.log('%c Merging PR', 'line-height: 30px;text-align: center;font-weight: bold');
    return this.request("".concat(this.originRepoURL, "/pulls/").concat(number, "/merge"), {
      method: 'PUT',
      body: JSON.stringify({
        commit_message: 'Automatically generated. Merged on Netlify CMS.',
        sha: headSha,
        merge_method: this.merge_method
      })
    }).catch(error => {
      if (error instanceof _netlifyCmsLibUtil.APIError && error.status === 405) {
        return this.forceMergePR(pullrequest, objects);
      } else {
        throw error;
      }
    });
  }

  forceMergePR(pullrequest, objects) {
    const files = objects.files.concat(objects.entry);
    const fileTree = this.composeFileTree(files);
    let commitMessage = 'Automatically generated. Merged on Netlify CMS\n\nForce merge of:';
    files.forEach(file => {
      commitMessage += "\n* \"".concat(file.path, "\"");
    });
    console.log('%c Automatic merge not possible - Forcing merge.', 'line-height: 30px;text-align: center;font-weight: bold');
    return this.getBranch().then(branchData => this.updateTree(branchData.commit.sha, '/', fileTree)).then(changeTree => this.commit(commitMessage, changeTree)).then(response => this.patchBranch(this.branch, response.sha));
  }

  getTree(sha) {
    if (sha) {
      return this.request("".concat(this.repoURL, "/git/trees/").concat(sha));
    }

    return Promise.resolve({
      tree: []
    });
  }
  /**
   * Get a blob from a tree. Requests individual subtrees recursively if blob is
   * nested within one or more directories.
   */


  getBlobInTree(treeSha, pathToBlob) {
    const pathSegments = pathToBlob.split('/').filter(val => val);
    const directories = pathSegments.slice(0, -1);
    const filename = pathSegments.slice(-1)[0];
    const baseTree = this.getTree(treeSha);
    const subTreePromise = directories.reduce((treePromise, segment) => {
      return treePromise.then(tree => {
        const subTreeSha = (0, _find2.default)(tree.tree, {
          path: segment
        }).sha;
        return this.getTree(subTreeSha);
      });
    }, baseTree);
    return subTreePromise.then(subTree => (0, _find2.default)(subTree.tree, {
      path: filename
    }));
  }

  toBase64(str) {
    return Promise.resolve(_jsBase.Base64.encode(str));
  }

  uploadBlob(item) {
    const content = (0, _result2.default)(item, 'toBase64', (0, _partial2.default)(this.toBase64, item.raw));
    return content.then(contentBase64 => this.request("".concat(this.repoURL, "/git/blobs"), {
      method: 'POST',
      body: JSON.stringify({
        content: contentBase64,
        encoding: 'base64'
      })
    }).then(response => {
      item.sha = response.sha;
      item.uploaded = true;
      return item;
    }));
  }

  updateTree(sha, path, fileTree) {
    return this.getTree(sha).then(tree => {
      let obj;
      let filename;
      let fileOrDir;
      const updates = [];
      const added = {};

      for (let i = 0, len = tree.tree.length; i < len; i++) {
        obj = tree.tree[i];

        if (fileOrDir = fileTree[obj.path]) {
          // eslint-disable-line no-cond-assign
          added[obj.path] = true;

          if (fileOrDir.file) {
            updates.push({
              path: obj.path,
              mode: obj.mode,
              type: obj.type,
              sha: fileOrDir.sha
            });
          } else {
            updates.push(this.updateTree(obj.sha, obj.path, fileOrDir));
          }
        }
      }

      for (filename in fileTree) {
        fileOrDir = fileTree[filename];

        if (added[filename]) {
          continue;
        }

        updates.push(fileOrDir.file ? {
          path: filename,
          mode: '100644',
          type: 'blob',
          sha: fileOrDir.sha
        } : this.updateTree(null, filename, fileOrDir));
      }

      return Promise.all(updates).then(tree => this.createTree(sha, tree)).then(response => ({
        path,
        mode: '040000',
        type: 'tree',
        sha: response.sha,
        parentSha: sha
      }));
    });
  }

  createTree(baseSha, tree) {
    return this.request("".concat(this.repoURL, "/git/trees"), {
      method: 'POST',
      body: JSON.stringify({
        base_tree: baseSha,
        tree
      })
    });
  }
  /**
   * Some GitHub API calls return commit data in a nested `commit` property,
   * with the SHA outside of the nested property, while others return a
   * flatter object with no nested `commit` property. This normalizes a commit
   * to resemble the latter.
   */


  normalizeCommit(commit) {
    if (commit.commit) {
      return _objectSpread({}, commit.commit, {
        sha: commit.sha
      });
    }

    return commit;
  }

  commit(message, changeTree) {
    const parents = changeTree.parentSha ? [changeTree.parentSha] : [];
    return this.createCommit(message, changeTree.sha, parents);
  }

  createCommit(message, treeSha, parents, author, committer) {
    return this.request("".concat(this.repoURL, "/git/commits"), {
      method: 'POST',
      body: JSON.stringify({
        message,
        tree: treeSha,
        parents,
        author,
        committer
      })
    });
  }

}

exports.default = API;

_defineProperty(API, "DEFAULT_COMMIT_MESSAGE", 'Automatically generated by Netlify CMS');

_defineProperty(API, "DEFAULT_PR_BODY", 'Automatically generated by Netlify CMS');